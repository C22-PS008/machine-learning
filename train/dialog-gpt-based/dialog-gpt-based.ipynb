{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install tokenizers\n",
    "!pip install datasets\n",
    "!pip install sentencepiece\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, TFGPT2Model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = TFGPT2Model.from_pretrained('gpt2')\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='tf')\n",
    "output = model(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-small\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"microsoft/DialoGPT-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "blended_skill_dataset = load_dataset(\"blended_skill_talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_skill_dataset_train, blended_skill_dataset_validation,blended_skill_dataset_test = blended_skill_dataset.split('train', 'validation', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_utterance_total=blended_skill_dataset_train['previous_utterance']+ blended_skill_dataset_validation['previous_utterance']+blended_skill_dataset_test['previous_utterance']\n",
    "free_messages_total=blended_skill_dataset_train['free_message']+ blended_skill_dataset_validation['free_message']+blended_skill_dataset_test['free_message']\n",
    "guided_messages_total=blended_skill_dataset_train['guide_message']+ blended_skill_dataset_validation['guide_message']+blended_skill_dataset_test['guide_message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dialogues=[]\n",
    "for i, free_message in enumerate(tqdm(free_messages_total)):\n",
    "    free_messages_list=[utterance.strip() for utterance in free_message if len(utterance.strip())>0]\n",
    "    guided_messages_list=[utterance.strip() for utterance in guided_messages_total[i] if len(utterance.strip())>0]\n",
    "    dialogue=previous_utterance_total[i]\n",
    "    \n",
    "    for j in range(len(free_messages_list)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, TFGPT2Model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = TFGPT2Model.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sumary()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
